using ForwardDiff
using CairoMakie

# Define Himmelblau's function
himmelblau(x, y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2
himmelblau_vec(v) = himmelblau(v[1], v[2])

# Gradient descent implementation
function gradient_descent(func, start_point; learning_rate=0.01, max_iterations=1000, tolerance=1e-6)
    current_point = copy(start_point)
    trajectory = [copy(current_point)]
    function_values = [func(current_point)]
    
    for iteration in 1:max_iterations
        grad = ForwardDiff.gradient(func, current_point)
        new_point = current_point - learning_rate * grad
        
        push!(trajectory, copy(new_point))
        push!(function_values, func(new_point))
        
        if norm(grad) < tolerance
            break
        end
        
        current_point = new_point
    end
    
    return trajectory, function_values
end

# Test with different starting points
starting_points = [
    [3.0, 2.0],
    [-2.8, 3.1],
    [-3.7, -3.2],
    [3.5, -1.8]
]

all_trajectories = []
all_function_values = []

for start in starting_points
    traj, fvals = gradient_descent(himmelblau_vec, start, learning_rate=0.001)
    push!(all_trajectories, traj)
    push!(all_function_values, fvals)
    
    final_point = traj[end]
    final_value = fvals[end]
    println("Start: $start â†’ Final: [$(round(final_point[1], digits=4)), $(round(final_point[2], digits=4))], f = $(round(final_value, digits=6))")
end

# Create convergence plot
figure = Figure(resolution=(800, 600))
axis = Axis(figure[1, 1],
    xlabel="Iteration",
    ylabel="Function Value",
    title="Gradient Descent Convergence - Himmelblau Function"
)

for (i, fvals) in enumerate(all_function_values)
    iterations = 0:length(fvals)-1
    lines!(axis, iterations, fvals, label="Run $(i)")
end

Legend(figure[1, 2], axis, "Starting Points")
figure