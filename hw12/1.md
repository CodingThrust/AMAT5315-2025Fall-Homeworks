# Snippet A: Poor performance due to repeated transfers
x_cpu = randn(10000)
for i in 1:100
    x_gpu = CuArray(x_cpu)    # Upload
    x_gpu .+= 1
    x_cpu = Array(x_gpu)       # Download
end

# Snippet B: Better performance with minimal transfers
x_gpu = CuArray(randn(10000))  # Upload once
for i in 1:100
    x_gpu .+= 1                # All on GPU
end
result = Array(x_gpu)          # Download once

# Kernel A: Warp divergence issue
function divergent_kernel(A)
    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x
    if i % 2 == 0
        A[i] = sin(A[i])    # Half of warp
    else
        A[i] = cos(A[i])    # Other half
    end
    return nothing
end

# Kernel B: Non-coalesced memory access
function bad_memory_kernel(A, B, stride)
    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x
    @inbounds if i <= length(A)
        B[i] = A[i * stride]  # Non-sequential access!
    end
    return nothing
end

# Improved thread ID calculation
function readable_kernel(A)
    block_offset = (blockIdx().x - 1) * blockDim().x
    thread_offset = threadIdx().x - 1
    i = block_offset + thread_offset + 1
    @inbounds if i <= length(A)
        A[i] = A[i] + 1
    end
    return nothing
end


# Approach A: Multiple kernel launches
x = CUDA.randn(10000)
y = x .^ 2
z = sin.(y)
w = z .+ 1

# Approach B: Single fused kernel
x = CUDA.randn(10000)
w = @. sin(x^2) + 1

# Approach C: Optimized library call
A = CUDA.randn(2000, 2000)
B = CUDA.randn(2000, 2000)
C = A * B  # Uses CUBLAS